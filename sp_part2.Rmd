---
title: "SP Test"
author: "Alejandro Jiménez Rico"
subtitle: Part 2
output:
  prettydoc::html_pretty:
    df_print: paged
    toc: yes
    theme: cayman
    highlight: vignette
  html_notebook:
    highlight: github
    theme: lumen
    toc: yes
  pdf_document:
    toc: yes
---

## Step 1

**Please calculate the 2nd day, 7th day and 10th day retention (which is the percentage of people that downloaded the game on day 1 who played again on day 2, 7 and 10). Please calculate the retention in two ways, using the user id (user_id) and then the device id (client_mobile_device_aid). (Please note that you only have the device id from the 14th of April).**

The first thing to do is to gather the data and organise it in data frames.

```{r message = FALSE}
library(data.table)
library(tidyverse)
library(lubridate)
library(viridis)

percent <- function(x, digits = 2, format = "f", ...) {
  paste0(formatC(100 * x, format = format, digits = digits, ...), "%")
}

raw.user <- fread('data/sh_user.csv')
raw.session <- fread('data/sh_session.csv')
raw.battles <- fread('data/sh_battles.csv')
```

Taking a brief look at the data.

```{r}
glimpse(raw.user)
glimpse(raw.session)
glimpse(raw.battles)
```

In order to measure the retention for each user, we have to compare the days each player has played with its registration day, so the first information we need to get clear is date of registration of every user.

```{r}
df.registration <- raw.user[,c("user_id", "date_register")]

```


For many different reasons, it could happen that a user registrates more than once. So we should check for duplicates.
```{r}

length(df.registration$user_id) - length(unique(df.registration$user_id))
df <- df.registration %>% 
	group_by(user_id) %>% 
	summarise(N=n())

unique(df$N)
```

There are 63 people who has been registered twice. Since we do not know how the databases are constructed, we need to learn a bit of these duplicates in order to make decisions properly.

```{r}
users.twice <- df[df[,2] == 2,1]
double.registration <- df.registration[df.registration$user_id %in% as.array(users.twice$user_id)]

double.registration <- double.registration %>% 
	group_by(user_id) %>% 
	summarise(unique = n_distinct(date_register))
	
unique(double.registration$unique)
```

We can see that those users who registered twice, did it both times on the same day. So we can discard duplicated registration records and move on, because we have double information about the same date.

```{r}
reg <- df.registration[!duplicated(df.registration[,'user_id']),]
rm(df,df.registration,double.registration,users.twice)
```

Once we have this data gathered, we need to format it properly in order to perform the exploratory analysis.

```{r}
con <- raw.session[,c("user_id", "datetime")]

df <- merge(reg,con)
df <- df %>% 
	mutate(date_register = ymd(date_register)) %>% 
	mutate(datetime = ymd(datetime))

df$ret <- df$datetime - df$date_register +1
df <- df %>% 
	mutate(ret = as.numeric(ret))
df <- df[,c(1,4)]
df <- df[!duplicated(df[,c('user_id','ret')]),]
```

Now we just plot the information and highlight *2nd*, *7th* and *10th* day retention.

```{r}
library(scales)
ret <- as.data.frame(table(df$ret))
ret$Freq <- as.numeric(ret$Freq/sum(ret$Freq))
ret$Var1 <- as.numeric(ret$Var1)
ret$colour <- ifelse(ret$Var1 == 2 | ret$Var1 == 7 | ret$Var1 == 10, "yellow", "blue")

gg <- ggplot(ret,  aes(x=order(Var1), y=Freq, fill=colour)) +
	geom_bar(stat="identity") +
	scale_y_continuous(labels = scales::percent_format()) +
	scale_x_continuous(limits=c(0,25)) +
	scale_fill_viridis(discrete = TRUE) +
	geom_text(aes(label=ifelse(Var1 == 2 | Var1 == 7 | Var1 == 10, percent(round(Freq, digits= 4)), "")), vjust = -0.15, hjust = +0.18, size = 5, position = position_dodge(width = 0)) +
	theme_bw() +
	labs(x = "Days", y = "Retention") +
	theme(legend.position = "NONE")
	
gg
```

## Step 2

**Please explain if the results are the same using the two different ids and if not why not.**

I am not entirely confident if I correctly unerstood the question. But at this point we should notice that it makes no sense whatsoever to group the users using their `device_id` in order to measure their retention, because we have only data from one day.

## Step 3

**Please explain how much of the variation in the 2nd day retention can be explained by
whether or not the user completed the tutorial on the 1st day and whether it is a significant variable
in understanding 2nd day retention. (You know if someone has complete the tutorial from the funnel
steps in the user file. We are interested in the variable called funnel_1d and anyone with a funnel
step higher than 2116 has completed the tutorial). You have to use a logistic regression.**

As always, the first step is to gather and format data properly.

```{r}
df.tutorial <- raw.user[,c("user_id", "funnel_1d")]
df.tutorial$tut <- ifelse(df.tutorial$funnel_1d > 2116, 1, 0)
df.tutorial$tut[is.na(df.tutorial$tut)] <- 0


pass.tutorial <- df.tutorial[,c(1,3)]
pass.tutorial$user_id <- as.factor(pass.tutorial$user_id)

ret2f <- df %>% 
	mutate(ret2 = ifelse(ret == 2, 1, 0)) %>% 
	group_by(user_id,ret2 )

ret2f$user_id <- as.factor(ret2f$user_id)

ret2 <- ret2f[,c(1,3)] %>% 
	group_by(user_id) %>% 
	summarise(ret2=sum(ret2))

tut.ret <- merge(pass.tutorial, ret2)
tut.ret$tut <- as.factor(tut.ret$tut)
tut.ret$ret2 <- as.factor(tut.ret$ret2)
```

Now we have the data ready for testing and doing regressions.

The first question to be answered now is whether or not these two variables we are considering are correlated. Our variables are cathegorical. This means that they do not express a magnitude, but a factor that labels a category. Two cathegorical variables can be correlated in the same sense as two numerical variables; but the statistical test performed for each case is quite different. 

To measure the dependence between cathegorical variables there is a widely used test, named *Chi-Squared Test*. Using this test, we can decide whether or not two cathegorical variables are correlated.

```{r}
library(MASS)
tb1 <- table(tut.ret$tut, tut.ret$ret2)
chisq.test(tb1)
```
The result of this test is plainly clear. This result states that these variables are not independent. Thus, we conclude that there is a relationship between having finished the tutorial and the 2nd day retention. 

I am fully aware that the question specificaly asked for a *Logistic Regression* in order to check this relationship, but I found interesting to start with a simpler statistical test and see if they agree.

Now, we can check further the relationship between these variables using a *Logistic Regression*. The point of using this regression is that is common to predict categorical outcomes using categorical variables. We can perform a Logistic Regression trying to predict whether or not some player have been retented the 2nd day since its regristration and determine if the `tutorial` variable (which is categorical) is useful for this prediction.

```{r}
model <- glm(tut.ret$ret2 ~ tut.ret$tut, family = binomial)
summary(model)
```

Considering the pvalue obtained, the variable that indicates whether or not a player was completed the tutorial is relevant to determine the 2nd day retention of that player.

Now that we know that the variable *is* relevant, we could ask *how much* relevant it is. Or, in other words, how 
much variation of the prediction on the 2nd day retention is caused by this variable. In Logistic Regression, technically we can not talk about any measure of *How much variation can be explained by this variable*. If we were talking about linear regression we could simply compute the $R^2$ and interpret its result as the percentage of the variation that could be explained with the variable; but there is no such thing in Logistic Regression. Notwithstanding, there are some so-called pseudo-$R^2$ as `Cox & Snell` and `Nagelkerke`.

Now we are going to apply the latter, since it is an adjustment of the former and thus more general. There are many different pseudo-$R^2$ for a Logistic Regression model, and each one of them has its flaws. Since the thorough analysis of them lands out of the scope of this project, we will simply use one whose usage in `R` straightforward and it has good documentation.

```{r}
library(rms)
x <- as.numeric(tut.ret$tut)
y <- as.numeric(tut.ret$ret2)
model2 <- lrm(y ~ x)
print(model2)
```

The output of this model leads to a Nagelkerke's $R^2= 0.196$. Could we say that a $19.60\%$ of the variance of the 2nd day retention can be explain from the variable that states whether or not a user has finished his tutorial? Technically, we should not [1], but it is the closest interpretation we can use [2] and it can be useful to compare the influence of different variables [1]. 

[1]: [*D.W. Hosmer and S. Lemeshow* (2000). Applied Logistic Regression](https://www.amazon.com/Applied-Logistic-Regression-Probability-Statistics/dp/0471356328)

[2]: [*Martina Mittlböck and Michael Schemper* (1996). Explained Variation for Logistic Regression. *Statistics in Medicine*. Volume 15: Pages 1987-1997](http://onlinelibrary.wiley.com.are.uab.cat/doi/10.1002/(SICI)1097-0258(19961015)15:19%3C1987::AID-SIM318%3E3.0.CO%3b2-9/full)

## Step 4:

**Please identify two other significant variables that we should look at to improve day 2 retention and quantify how mmuch of the variation in retention can be explained by these variables.**

Once we know how to measure the relevancy of one variable and we have accepted it, we can look further for more variables to consider.

As always, gathering and good formatting of data in order to perform the logistic regression. In this case, we will give a try to the `registration platform` and to the `country` of the user.

```{r}

x <- raw.user[,c("user_id", "register_platform", "register_ip_country")]
x$user_id <- as.factor(x$user_id)
x$register_platform <- as.factor(x$register_platform)
x$register_ip_country <- as.factor(x$register_ip_country)

df <- merge(tut.ret, x, by = "user_id", all.x = TRUE)

# Clean duplicates
df <- df[!duplicated(df),]

# Perform Logistic Regression
rm(df.tutorial, model, model2, pass.tutorial, reg, ret, ret2, ret2f, tut.ret, x, tb1, y)
model <- glm(df$ret2 ~ df$register_platform + df$register_ip_country + df$tut, family = binomial)
summary(model)
```

It can be noticed that the country of the user is not a relevant variable to determine the 2nd day retention whatsoever. So we now drop those variables that have not been relevant enough.

```{r}
imp.var <- df[,-c("register_ip_country")]
```

And repeat the regression.

```{r}
model <- glm(df$ret2 ~ df$register_platform + df$tut, family = binomial)
summary(model)
```
Whereas the `tutorial` variable relevance is out of doubt, this variable concerning the platform in which the game has been installed is relevant just by the standard metrics (pvalue below $0.05$). All in all, we can confirm the relevancy of our variables and continue.

Let's find some other useful variables. For this purpose, we build variables out of the `register date`. From this feature we can deducte the month in which the user registered, the year and the day of the week.

```{r}
x <- raw.user[,c("user_id", "date_register")]
x$user_id <- as.factor(x$user_id)
x$date_register <- date(x$date_register)
x$month_register <- as.factor(month(x$date_register))
x$year_register <- as.factor(year(x$date_register))
x$wday_register <- as.factor(weekdays(x$date_register))

df <- merge(imp.var, x)

# Clean duplicates and NA
df <- df[!duplicated(df),]
df <- na.omit(df)

model <- glm(df$ret2 ~ df$tut + df$register_platform + df$month_register + df$year_register + df$wday_register, family=binomial)

summary(model)
```

Turns out that the `month` and the `year` in which a user has been registered is of no importance in order to predict the 2nd day retention. What it is interesting is the great importance of the day of the week in which the registration was made. Let's isolate a bit the non-relevant variables and see with more detail what happens to this `weekday` variable.

```{r}
df <- df[,-c("month_register", "year_register")]
```

```{r}
model <- glm(df$ret2 ~ df$tut + df$register_platform + df$wday_register, family=binomial)

summary(model)
```
Interesting enough, not all days are equally important. But some of them are undoubtedly relevant.

In order to measure the pseudeo-R squared as we did before, we need to create dummy variables out of our actual variables.

```{r}
library(dummies)
dum.df <- df[,c("user_id", "tut", "ret2")]

dum.df <- cbind(dum.df, dummy(df$register_platform, sep="_"))

dum.df <- cbind(dum.df, dummy(df$wday_register, sep="_"))
```

And simply perform the logistic regression again

```{r}
test <- dum.df[,-c("user_id")]
test$tut <- as.numeric(as.character(test$tut))

colnames(test) <- c("tut", "ret2", "android", "ios", "friday", "monday", "saturday", "sunday", "thursday", "tuesday", "wednesday") 

modeltut <- lrm(formula = test$ret2 ~ test$tut)
modelwed <- lrm(formula = test$ret2 ~ test$wednesday)
modelmon <- lrm(formula = test$ret2 ~ test$monday)
modeltue <- lrm(formula = test$ret2 ~ test$tuesday)

paste("Tutorial: R^2 = ", modeltut$stats[10])
paste("Mondays: R^2 = ", modelmon$stats[10])
paste("Tuesdays: R^2 = ", modeltue$stats[10])
paste("Wednesdays: R^2 = ", modelwed$stats[10])

```

Despite that the statistical tests stated that these are relevant variables, we can notice how small their pseudo-$R^2$ are, compared to our first variable. This leads to the conclusion that `tutorial` is the most relevant variable to explain the variance of the 2nd day retention.


